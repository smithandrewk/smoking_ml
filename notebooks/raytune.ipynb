{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lib.imports import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    skip_idx = [19,24,26,32,34,38,40,45,52,55,70]\n",
    "    all_idx = list(range(71))\n",
    "    for idx in skip_idx:\n",
    "        all_idx.remove(idx)\n",
    "    random.seed(0)\n",
    "    random.shuffle(all_idx)\n",
    "    k_folds = 5\n",
    "    foldi = 0\n",
    "    fold_size = int(len(all_idx)/k_folds)\n",
    "    test_idx = all_idx[foldi*fold_size:(foldi+1)*fold_size]\n",
    "    for idx in test_idx:\n",
    "        all_idx.remove(idx)\n",
    "    train_idx = all_idx\n",
    "    window_size = 101\n",
    "    X,y = load_and_window_nursing_list(train_idx,window_size=window_size,data_dir=f'/home/andrew/smoking/data/nursingv1/',label_dir=f'/home/andrew/smoking/data/nursingv1_andrew/')\n",
    "    X_train,X_dev,y_train,y_dev = train_test_split(X,y,test_size=.05,stratify=y,random_state=0)\n",
    "\n",
    "    return X_train,X_dev,y_train,y_dev,test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(config,data_dir=None):\n",
    "    model = MLP(window_size=101)\n",
    "    device = 'cuda'\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=config[\"lr\"])\n",
    "\n",
    "    checkpoint = session.get_checkpoint()\n",
    "\n",
    "    if checkpoint:\n",
    "        checkpoint_state = checkpoint.to_dict()\n",
    "        start_epoch = checkpoint_state[\"epoch\"]\n",
    "        model.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    X_train,X_dev,y_train,y_dev,test_idx = load_data()\n",
    "\n",
    "    trainloader = DataLoader(TensorDataset(X_train,y_train),batch_size=config['batch_size'],shuffle=True)\n",
    "    devloader = DataLoader(TensorDataset(X_dev,y_dev),batch_size=config['batch_size'],shuffle=True)\n",
    "\n",
    "    pbar = tqdm(range(start_epoch,10))\n",
    "\n",
    "    for epoch in pbar:\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\n",
    "                    \"[%d, %5d] loss: %.3f\"\n",
    "                    % (epoch + 1, i + 1, running_loss / epoch_steps)\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(devloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        checkpoint_data = {\n",
    "            \"epoch\": epoch,\n",
    "            \"net_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }\n",
    "        checkpoint = Checkpoint.from_dict(checkpoint_data)\n",
    "\n",
    "        session.report(\n",
    "            {\"loss\": val_loss / val_steps},\n",
    "            checkpoint=checkpoint,\n",
    "        )\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def main(num_samples=1, max_num_epochs=5, gpus_per_trial=1):\n",
    "    config = {\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([16,32,64,128]),\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "    result = tune.run(\n",
    "        partial(train_mlp),\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(f\"Best trial config: {best_trial.config}\")\n",
    "    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "    print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n",
    "\n",
    "    best_trained_model = MLP(window_size=101)\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint = best_trial.checkpoint.to_air_checkpoint()\n",
    "    best_checkpoint_data = best_checkpoint.to_dict()\n",
    "\n",
    "    best_trained_model.load_state_dict(best_checkpoint_data[\"net_state_dict\"])\n",
    "\n",
    "    # test_acc = test_accuracy(best_trained_model, device)\n",
    "    # print(\"Best trial test set accuracy: {}\".format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-05-22 13:03:22</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:42.94        </td></tr>\n",
       "<tr><td>Memory:      </td><td>14.2/31.3 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 4.000: -0.11897307399844066 | Iter 2.000: -0.12247936796571425 | Iter 1.000: -0.1293827498828011<br>Logical resource usage: 0/24 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mlp_c290c_00000</td><td>TERMINATED</td><td>192.168.1.148:25221</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000104125</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         341.084</td><td style=\"text-align: right;\">0.119332</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m E0522 12:57:41.361542416   25255 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m E0522 12:57:41.372231545   25255 fork_posix.cc:76]           Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1,  2000] loss: 0.326\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1,  4000] loss: 0.133\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1,  6000] loss: 0.082\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1,  8000] loss: 0.056\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 10000] loss: 0.041\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 12000] loss: 0.032\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 14000] loss: 0.026\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 16000] loss: 0.021\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 18000] loss: 0.018\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 20000] loss: 0.016\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 22000] loss: 0.014\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 24000] loss: 0.012\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 26000] loss: 0.011\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 28000] loss: 0.010\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 30000] loss: 0.009\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 32000] loss: 0.009\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 34000] loss: 0.008\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 36000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 38000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 40000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 42000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [1, 44000] loss: 0.006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">    loss</th><th>node_ip      </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mlp_c290c_00000</td><td>2023-05-22_13-03-22</td><td>True  </td><td>tau       </td><td style=\"text-align: right;\">                         5</td><td style=\"text-align: right;\">0.119332</td><td>192.168.1.148</td><td style=\"text-align: right;\">25221</td><td>True               </td><td style=\"text-align: right;\">             341.084</td><td style=\"text-align: right;\">           62.2923</td><td style=\"text-align: right;\">       341.084</td><td style=\"text-align: right;\"> 1684775002</td><td style=\"text-align: right;\">                   5</td><td>c290c_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:07<10:03, 67.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2,  2000] loss: 0.133\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2,  4000] loss: 0.065\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2,  6000] loss: 0.043\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2,  8000] loss: 0.032\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 10000] loss: 0.026\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 12000] loss: 0.021\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 14000] loss: 0.019\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 16000] loss: 0.016\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 18000] loss: 0.014\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 20000] loss: 0.013\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 22000] loss: 0.012\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 24000] loss: 0.010\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 26000] loss: 0.010\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 28000] loss: 0.009\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 30000] loss: 0.008\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 32000] loss: 0.008\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 34000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 36000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 38000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 40000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 42000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [2, 44000] loss: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:12<08:48, 66.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3,  2000] loss: 0.122\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3,  4000] loss: 0.063\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3,  6000] loss: 0.041\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3,  8000] loss: 0.031\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 10000] loss: 0.025\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 12000] loss: 0.021\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 14000] loss: 0.018\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 16000] loss: 0.016\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 18000] loss: 0.014\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 20000] loss: 0.012\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 22000] loss: 0.011\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 24000] loss: 0.010\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 26000] loss: 0.010\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 28000] loss: 0.009\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 30000] loss: 0.008\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 32000] loss: 0.008\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 34000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 36000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 38000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 40000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 42000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [3, 44000] loss: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:14<07:29, 64.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4,  2000] loss: 0.121\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4,  4000] loss: 0.059\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4,  6000] loss: 0.041\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4,  8000] loss: 0.031\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 10000] loss: 0.025\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 12000] loss: 0.021\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 14000] loss: 0.018\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 16000] loss: 0.016\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 18000] loss: 0.014\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 20000] loss: 0.012\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 22000] loss: 0.011\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 24000] loss: 0.010\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 26000] loss: 0.009\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 28000] loss: 0.009\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 30000] loss: 0.008\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 32000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 34000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 36000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 38000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 40000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 42000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [4, 44000] loss: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [04:17<06:21, 63.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5,  2000] loss: 0.117\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5,  4000] loss: 0.059\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5,  6000] loss: 0.039\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5,  8000] loss: 0.030\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 10000] loss: 0.024\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 12000] loss: 0.020\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 14000] loss: 0.017\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 16000] loss: 0.015\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 18000] loss: 0.013\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 20000] loss: 0.012\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 22000] loss: 0.011\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 24000] loss: 0.010\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 26000] loss: 0.009\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 28000] loss: 0.008\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 30000] loss: 0.008\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 32000] loss: 0.008\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 34000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 36000] loss: 0.007\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 38000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 40000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 42000] loss: 0.006\n",
      "\u001b[2m\u001b[36m(func pid=25221)\u001b[0m [5, 44000] loss: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 13:03:22,442\tINFO tune.py:945 -- Total run time: 342.95 seconds (342.93 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 0.00010412540797618336, 'batch_size': 32}\n",
      "Best trial final validation loss: 0.11933238725527238\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/andrew/smoking/smoking_ml/baseline_mlp_cv.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/andrew/smoking/smoking_ml/baseline_mlp_cv.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m main()\n",
      "\u001b[1;32m/home/andrew/smoking/smoking_ml/baseline_mlp_cv.ipynb Cell 6\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrew/smoking/smoking_ml/baseline_mlp_cv.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest trial config: \u001b[39m\u001b[39m{\u001b[39;00mbest_trial\u001b[39m.\u001b[39mconfig\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrew/smoking/smoking_ml/baseline_mlp_cv.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest trial final validation loss: \u001b[39m\u001b[39m{\u001b[39;00mbest_trial\u001b[39m.\u001b[39mlast_result[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/andrew/smoking/smoking_ml/baseline_mlp_cv.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest trial final validation accuracy: \u001b[39m\u001b[39m{\u001b[39;00mbest_trial\u001b[39m.\u001b[39mlast_result[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrew/smoking/smoking_ml/baseline_mlp_cv.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m best_trained_model \u001b[39m=\u001b[39m MLP(window_size\u001b[39m=\u001b[39m\u001b[39m101\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrew/smoking/smoking_ml/baseline_mlp_cv.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "f1i = []\n",
    "recalli = []\n",
    "precisioni = []\n",
    "for idx in test_idx:\n",
    "    X,y = load_and_window_nursing_list([idx])\n",
    "    loss,y_true,y_pred = test_evaluation(DataLoader(TensorDataset(X,y),batch_size=32,shuffle=True),model,criterion,plot=True)\n",
    "    f1i.append(f1_score(y_true=y_true,y_pred=y_pred.round(),average='macro'))\n",
    "    recalli.append(recall_score(y_true=y_true,y_pred=y_pred.round(),average='macro'))\n",
    "    precisioni.append(precision_score(y_true=y_true,y_pred=y_pred.round(),average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(recalli,bw_adjust=.4)\n",
    "sns.rugplot(recalli)\n",
    "print(torch.tensor(recalli).mean()) #.4958\n",
    "print(torch.tensor(recalli).std()) #.0063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(f1i,bw_adjust=.4)\n",
    "sns.rugplot(f1i)\n",
    "print(torch.tensor(f1i).mean()) #.4958\n",
    "print(torch.tensor(f1i).std()) #.0063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(precisioni,bw_adjust=.4)\n",
    "sns.rugplot(precisioni)\n",
    "print(torch.tensor(precisioni).mean()) #.4958\n",
    "print(torch.tensor(precisioni).std()) #.0063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
